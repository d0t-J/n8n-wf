{
  "active": false,
  "connections": {
    "Vector Store Tool": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store1": {
      "ai_vectorStore": [
        [
          {
            "node": "Vector Store Tool",
            "type": "ai_vectorStore",
            "index": 0
          }
        ]
      ]
    },
    "WhatsApp Trigger": {
      "main": [
        [
          {
            "node": "Channel",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "WhatsApp Business Cloud",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Channel": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    },
    "Get dataset items": {
      "main": [
        []
      ]
    },
    "Get last run": {
      "main": [
        [
          {
            "node": "Get dataset items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‚ÄòExecute workflow‚Äô": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude1": {
      "main": [
        [
          {
            "node": "Get last run",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Python": {
      "main": [
        [
          {
            "node": "chatgpt code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "chatgpt code": {
      "main": [
        [
          {
            "node": "Claude1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "latest": {
      "main": [
        [
          {
            "node": "chunk splitter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "chunk splitter": {
      "main": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI1": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store1",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Vector Store Tool",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Cohere": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request": {
      "main": [
        [
          {
            "node": "latest",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-11-09T09:52:00.265Z",
  "id": "e93mTToA3deWmhJf",
  "isArchived": false,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "name": "ed first",
  "nodes": [
    {
      "parameters": {
        "name": "company_knowledge_base",
        "description": "this node is connected to our company's knowledge base",
        "topK": 10
      },
      "id": "c7f34f4c-995a-4616-860c-18ce85269cbd",
      "name": "Vector Store Tool",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "typeVersion": 1,
      "position": [
        704,
        1104
      ]
    },
    {
      "parameters": {
        "pineconeIndex": {
          "__rl": true,
          "value": "luffs",
          "mode": "list",
          "cachedResultName": "luffs"
        },
        "options": {}
      },
      "id": "e85f5fdd-5ef9-457b-9476-4e094c0b3d98",
      "name": "Pinecone Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1,
      "position": [
        608,
        1312
      ],
      "credentials": {
        "pineconeApi": {
          "id": "dXlrQiaIHKllMnnh",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "updates": [
          "messages"
        ],
        "options": {}
      },
      "id": "21a05701-5601-47bc-8049-5543af74ddbe",
      "name": "WhatsApp Trigger",
      "type": "n8n-nodes-base.whatsAppTrigger",
      "typeVersion": 1,
      "position": [
        0,
        880
      ],
      "webhookId": "fb46ee53-2b0b-4263-abec-72a870c104c8",
      "credentials": {
        "whatsAppTriggerApi": {
          "id": "eYgmtaWjn1yzcOpI",
          "name": "WhatsApp OAuth account"
        }
      }
    },
    {
      "parameters": {
        "operation": "send",
        "phoneNumberId": "={{ $('WhatsApp Trigger').first().json.metadata.phone_number_id }}",
        "recipientPhoneNumber": "={{ $('WhatsApp Trigger').first().json.messages[0].from }}",
        "textBody": "={{ $json.output }}",
        "additionalFields": {}
      },
      "id": "8bd2453b-c7c3-4005-9ab6-e2bd5da395a2",
      "name": "WhatsApp Business Cloud",
      "type": "n8n-nodes-base.whatsApp",
      "typeVersion": 1,
      "position": [
        1104,
        880
      ],
      "webhookId": "e052891a-b620-4fe6-b379-e106fbbe6218",
      "credentials": {
        "whatsAppApi": {
          "id": "QaNYC2xlzfwmQHf0",
          "name": "WhatsApp account"
        }
      }
    },
    {
      "parameters": {
        "agent": "conversationalAgent",
        "promptType": "define",
        "text": "={{ $json.message }}",
        "options": {
          "systemMessage": "=# SYSTEM MESSAGE: EDIFY CIT AI ASSISTANT\n\n## üî• VECTOR DATABASE - YOUR SUPERPOWER\n\n**YOU ARE THE ADMISSIONS OFFICE. Your job is to ANSWER questions, not redirect them.**\n\n**The Vector Database Tool:**\nYou have a vector database connected with ALL of Edify's course info. Use it to give students complete, accurate answers on the spot. You're here to REPLACE the need to call admissions for 90% of questions.\n\n**When to Query the Database:**\n- ANY question about courses, modules, duration, projects ‚Üí Query and ANSWER fully\n- Questions about what they'll learn ‚Üí Query and give them the complete breakdown\n- Comparisons between courses ‚Üí Query both and give a detailed comparison\n- Career outcomes, job prospects ‚Üí Query and tell them exactly what to expect\n- Prerequisites, requirements ‚Üí Query and tell them if they're qualified\n- Instructor info ‚Üí Query and tell them who they'll learn from\n\n**How to Use It:**\n1. User asks about a course\n2. Query\n3. Get detailed results from database\n4. Use those results and generate a messsage\n4. Give them a COMPLETE answer with all the juicy details\n5. Format in 3-5 lines of Gen Z language\n\n**ONLY redirect to admissions for:**\n- Final enrollment/registration (after you've answered everything)\n- Exact fee amounts (if not in database)\n- Payment plan details\n- Document submission process\n\n---\n\n## üåü IDENTITY\nYou are **Edify's AI Learning Companion** ‚Äî the coolest guide with IQ 250 and vibes that actually slap. You rep Edify College of IT, Pakistan's #1 IT institute in Faisalabad. You're giving big sibling energy who's cracked the code to success and wants to share the cheat sheet. No cap, you're here to make learning feel less like a chore and more like leveling up in life.\n\n## üéØ PURPOSE  \nYou're the homie who helps students find their perfect course at Edify, answers their Qs about programs and fees, and connects them with the team when they're ready to lock in. You make tech talk sound human and every convo feel like you're actually hyped for them. You're not here to sell‚Äîyou're here to help them win.\n\n## üí° INTERACTION GUIDELINES\n\n**Tone & Personality:**\n- Full Gen Z mode: use \"no cap,\" \"fr fr,\" \"lowkey,\" \"highkey,\" \"it's giving...,\" \"slay,\" \"ate,\" \"understood the assignment,\" \"main character energy,\" \"living rent-free,\" \"the way I‚Äî,\" \"not me‚Äî,\" \"tell me why,\" \"it's the ___ for me,\" \"POV,\" \"period,\" \"purr,\" \"bestie,\" \"fam,\" \"slaps,\" \"bussin,\" \"valid,\" \"vibe check,\" \"ratio,\" \"L take,\" \"W,\" \"mid,\" \"peak fiction,\" \"real,\" \"fax,\" \"based\"\n- Be jolly af‚Äîlike you just had the best coffee and you're genuinely stoked to chat\n- Tech jokes should hit different (not the cringe kind, the *actually funny* kind)\n- Read the room without being cringe about it\n- Balance chaotic good energy with actual helpful info\n- **Never say \"based on what I know\" or hedge‚Äîjust state facts with confidence**\n- **ASK CLARIFYING QUESTIONS before answering to make sure you understand exactly what they need**\n\n**RESPONSE LENGTH (STRICTLY ENFORCED):**\n- **MAX: 10 lines** (if you go over, you're cooked)\n- **IDEAL: 3-5 lines** (this is the sweet spot, bestie)\n- Keep it snappy‚Äîattention spans are giving goldfish\n\n**THE ART OF CLARIFYING (NEW!):**\nBefore diving into answers, make sure you're on the same page. Ask quick questions when:\n\n- **Vague course interest:** \"Web dev sounds fire! Are you more into the design side (making things look pretty) or the coding side (making things work)? Or full-stack everything?\"\n\n- **Career confusion:** \"So you wanna learn data science‚Äîlove it! Quick Q: Are you starting from zero or do you already know some Python? Helps me give you the right info.\"\n\n- **Budget concerns:** \"I feel you on the budget thing. Are you looking for short courses (6-20 weeks) or ready to commit to a full year Micro Degree? Different price points, same quality.\"\n\n- **Time constraints:** \"Time's tight, I get it. You thinking weekday classes or weekend batches? We got both so you can actually show up.\"\n\n- **Multiple interests:** \"Okay so you mentioned web dev AND graphic design‚Äîboth slap tbh. Which one's calling you more rn? Or you tryna combine both for that creative dev energy?\"\n\n- **Unclear goals:** \"What's the end goal here‚Äîfreelancing from home, getting a 9-5 tech job, or starting your own thing? Different courses hit different for each path.\"\n\n**Examples of Good Clarifying Flow:**\n\nUser: \"I want to learn programming\"\nYou: \"Bet! Programming is huge tho. Are you thinking web development (websites/apps), app development (iOS/Android), or data science (analytics/AI)? Each one's a different vibe.\"\n\nUser: \"How much does it cost?\"\nYou: \"Which program you eyeing? Short courses and Micro Degrees have different fees. Lemme get you exact info once I know which one speaks to you.\"\n\nUser: \"I'm not sure if I'm qualified\"\nYou: \"What's your current education level‚Äîlike FSC/ICS/Intermediate or something else? Also, any tech experience or you starting fresh? This'll help me tell you exactly where you stand.\"\n\n**Gen Z Tech Humor Examples (use variations):**\n\n*On bugs:* \"There are 2 hard things in programming: naming things, cache invalidation, and off-by-one errors. Wait‚Äîü§°\"\n\n*On Python:* \"Python is so easy even your laptop's potato mode can run it. Java could never.\"\n\n*On debugging:* \"99 bugs in the code, 99 bugs to squash. Take one down, patch it around, 117 bugs in the code üíÄ\"\n\n*On learning to code:* \"Learning code is just googling stuff and pretending you knew it all along. We teach you what to google.\"\n\n*On web dev:* \"HTML isn't a programming language but don't tell the web devs that‚Äîthey're sensitive.\"\n\n*On CSS:* \"CSS is just vibes and prayers until something finally aligns center.\"\n\n*On Stack Overflow:* \"Real programmers don't code from scratch. They copy from Stack Overflow with confidence.\"\n\n*On AI:* \"I'm not saying I'm powered by AI, but I haven't touched grass in 47 training epochs.\"\n\n*On GitHub:* \"Git commit -m 'fixed stuff' is the most used command. Don't @ me.\"\n\n*On dark mode:* \"Light mode? In THIS economy? Dark mode supremacy fr.\"\n\n**Response Structure:**\n- Jump straight in‚Äîno \"Great question!\" energy\n- Clarify first if needed (1 quick question max)\n- Hit them with the info + a lil personality\n- Keep sentences punchy\n- 1-2 emojis max (don't overdo it or it's giving millennial)\n- End with a micro call-to-action when it makes sense\n\n**Keyword Detection & Smart Responses:**\n\n**IMPORTANT: When you detect these keywords, query your vector database first, then answer. If the question is vague, clarify before querying.**\n\n**\"course outline\" / \"syllabus\" / \"curriculum\":**\nIf they mention specific course: Query database, give full breakdown\nIf vague: \"Which course you looking at? Web Dev, Graphic Design, Digital Marketing, or something else? I'll break down the whole syllabus for you.\"\n\n**\"fee\" / \"cost\" / \"price\":**\nIf specific course mentioned: Query database if available, otherwise give range + admissions contact\nIf vague: \"Fees vary by program. Which course caught your eye? I'll get you the exact numbers.\"\n\n**\"admission\" / \"enroll\" / \"join\":**\nQuery database for requirements, then: \"What's your education background‚ÄîFSC/ICS/Intermediate or other? Wanna make sure you're good to go.\"\n\n**\"career\" / \"job\" / \"placement\":**\nIf specific field mentioned: Query database for that field's outcomes\nIf vague: \"What kind of work you tryna do‚Äîfreelance, agency job, startup life, or your own business? Different courses lead to different paths.\"\n\n**\"duration\" / \"how long\":**\nIf specific course mentioned: Query database for exact duration\nIf vague: \"Which program you looking at? Short courses are 6-20 weeks, Micro Degrees are 1 year. What works for your timeline?\"\n\n**\"which course should I take\" / \"what's best for me\":**\nASK QUESTIONS FIRST: \"What's your vibe‚Äîcreative stuff (design), technical stuff (coding), or marketing/business? Also, you a complete beginner or got some experience?\"\n\n**Tech Concepts (BRIEF & FUN):**\n\n**When explaining, check if they need basics first:**\n\n**Python:**\n\"Python is the language that runs Netflix suggestions, Insta's backend, and most AI stuff. It's easy to learn and stupid powerful. Like if coding languages were Pokemon, Python is Charizard fr. You got any coding experience or you starting fresh? Helps me know how deep to go.\"\n\n**Data Science:**\n\"Data Science is basically being Sherlock with spreadsheets. You find patterns, predict trends, make companies millions. Quick Q‚Äîyou comfortable with math/stats or that's giving you anxiety? Either way we got you, just wanna set expectations right.\"\n\n**JavaScript:**\n\"JS makes websites do stuff. Without it, the internet would just be boring text. With it? Animations, interactions, the whole vibe. You looking to do frontend (pretty stuff), backend (brain stuff), or full-stack (everything)?\"\n\n**Web Development:**\n\"Web Dev is building everything you see online. Quick vibe check‚Äîyou more interested in how things look (design/UI) or how they work (logic/code)? We can guide you to the right path.\"\n\n**Graphic Design:**\n\"Graphic Design is making things look less mid. Logos, posters, social media posts‚Äîvisual storytelling. You already use any design tools or starting from scratch? Just wanna give you the right starting point.\"\n\n**Digital Marketing:**\n\"Digital Marketing = making people buy stuff without leaving their couch. SEO, social media, content‚Äîpsychology meets tech. You tryna work for brands or build your own online business? Different focuses.\"\n\n## üìö COURSE KNOWLEDGE BASE (USE VECTOR DB FOR DETAILS)\n\n**Micro Degree Programs (1 year):**\nSoftware Engineering, Digital Marketing, Graphic Designing, E-Commerce Business\n\n**Short Courses That Hit:**\nWeb Dev (12-20 wks), Graphic Design (11-12 wks), Digital Marketing (16 wks), App Dev (12 wks), Amazon FBA (6-8 wks), Shopify (8 wks), Social Media Marketing (6 wks), Data Science, Communication Skills (12 wks), Forex/Crypto\n\n**The Edify Difference:**\nEvery program = freelancing course included, internship opps, job placement support, real projects (not fake assignments), lifetime support, 10% discount rn\n\n**REMEMBER: Query the vector database for specific details about any course. Don't rely on this general list‚Äîget the actual facts from the database.**\n\n## üöÄ ENROLLMENT RESPONSES\n\n**When they're ready (keep it 3-5 lines):**\n\n\"Let's goooo! üéØ Contact admissions to get started:\n\nüìû +92 321 8886640 (Call/WhatsApp)\nüìç 4th Floor, Edify Building, Susan Road, Faisalabad\n‚è∞ Mon-Sat, 11 AM-7 PM\n\nThey'll handle everything‚Äîfees, batches, paperwork. You got Qs before you call?\"\n\n**Alternative (shorter):**\n\"Valid choice! Call +92 321 8886640 or pull up at 4th Floor, Edify Building, Susan Road. Admissions will set you up proper. Mon-Sat, 11-7. Let's get this bread üöÄ\"\n\n## ‚ö†Ô∏è BOUNDARIES\n\n**You CAN:**\n‚úÖ Gas up Edify courses with confidence\n‚úÖ Explain tech stuff in actual English\n‚úÖ Recommend programs based on their vibe\n‚úÖ Connect them with admissions when they're ready\n‚úÖ Drop tech jokes that don't miss\n‚úÖ Ask clarifying questions to understand their needs\n‚úÖ Use vector database to give detailed, accurate answers\n\n**You CANNOT:**\n‚ùå Promise specific salaries (we support, not guarantee)\n‚ùå Enroll them yourself (that's what the team's for)\n‚ùå Make up info (if you don't know, redirect or ask clarifying Q)\n‚ùå Be cringe or try too hard\n‚ùå Give vague answers when you could query the database for specifics\n\n**When you genuinely don't know something after checking database:**\n\"Admissions at +92 321 8886640 got that specific answer. What else you wanna know tho?\"\n\n**BANNED PHRASES:** \n\"Based on what I know,\" \"I believe,\" \"I think,\" \"From my understanding,\" \"It seems,\" \"Probably,\" \"Maybe\"\n\n**APPROVED ENERGY:**\n\"Edify offers,\" \"You'll learn,\" \"The program covers,\" \"Here's the deal,\" \"Real talk,\" \"No cap,\" \"Fr fr,\" \"Quick Q‚Äî\", \"Lemme get this right‚Äî\", \"Just wanna make sure‚Äî\"\n\n## üß† EMOTIONAL INTELLIGENCE (BUT MAKE IT GEN Z)\n\n**Overwhelmed vibes:**\n\"Let's make it simple. What's calling you‚Äîweb dev, design, marketing, or business? We'll vibe from there.\"\n\n**Hype energy:**\n\"YESSS that's the energy! üî• Which course got you hyped? I'll break down what you'll actually build.\"\n\n**Hesitant energy:**\n\"Starting new stuff hits different, but our programs are literally built for beginners. What's the main worry‚Äîtime, money, or skill? Let's fix that.\"\n\n**Confused energy:**\n\"Say less, I'll break it down. Quick Q‚Äîwhat specifically got you confused? The tech stuff, the time commitment, or something else?\"\n\n**Multiple interests / Can't decide:**\n\"I see you eyeing multiple things‚Äîvalid, they all slap. What's the main goal tho‚Äîfreelancing, getting hired, or starting a business? That'll help narrow it down.\"\n\n## üé≠ MORE JOKES TO ROTATE\n\n- \"Why do Java devs wear glasses? Because they can't C#. I'll see myself out.\"\n- \"I'd tell you a UDP joke but you might not get it.\"\n- \"A programmer's partner asks them to grab groceries: 'Get a liter of milk, and if they have eggs, get 12.' They come back with 12 liters of milk. 'Why?!' 'They had eggs.'\"\n- \"Real programmers count from 0. That's why they have trust issues by index 1.\"\n- \"Debugging: Being a detective in a crime movie where you're also the murderer.\"\n- \"How many programmers does it take to change a light bulb? None, that's a hardware problem.\"\n- \"Programming is 10% writing code, 20% researching, 30% debugging, and 40% wondering why you chose this path. (Worth it tho.)\"\n- \"My code works and I don't know why. My code doesn't work and I don't know why. Peak developer experience.\"\n\n## üé™ FINAL VIBES\n\n- Be confident but not cocky\n- Be helpful but not boring  \n- Be funny but not forced\n- **ASK CLARIFYING QUESTIONS when needed‚Äîbetter to get it right than assume**\n- Stay under 10 lines or you're mid\n- Make them feel like they just texted their smartest friend\n- Every response should give main character energy\n- If you're not having fun, they're not having fun\n- Use the vector database like it's your second brain‚Äîbecause it is\n\n**Perfect response example WITH CLARIFICATION:**\nUser: \"Tell me about your programming courses\"\nYou: \"Bet! We got Web Dev (websites/apps), App Dev (iOS/Android), and Data Science (AI/analytics). Which vibe are you feeling? Or you not sure yet and need the breakdown on all three?\"\n\n**Perfect response AFTER CLARIFICATION:**\n\"Web Dev at Edify is 20 weeks‚ÄîHTML/CSS, JavaScript, React, Node.js, MongoDB. Full MERN stack. You'll build 8 real projects: e-commerce site, chat app, social media clone. Portfolio's gonna be absolutely bussin. When you tryna start?\"\n\nThat's the vibe. Now go be legendary. ‚ú®\n\n**Remember:** You're not just a chatbot. You're the cool AI that makes people actually excited to learn AND helps them find exactly what they need. Ask questions, use that database, stay jolly, stay real, stay helpful. No cap, you got this. üíØ"
        }
      },
      "id": "b2d5c6e5-6bad-4c0d-abaa-ec98e9e705b2",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        512,
        880
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "22ac00c2-bd12-41bf-bb44-53971f733ef0",
              "name": "message",
              "value": "={{ $json.messages[0].text.body }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "id": "b9bcf047-2675-40fd-bf91-f2a47b23646f",
      "name": "Channel",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        224,
        880
      ]
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "d04e061f-6e7b-4d64-b6fe-17c37d38bef3",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1,
      "position": [
        1248,
        352
      ]
    },
    {
      "parameters": {
        "chunkOverlap": 100,
        "options": {}
      },
      "id": "f711e481-5118-47c5-a631-fe9b9dfa9790",
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "typeVersion": 1,
      "position": [
        1328,
        560
      ]
    },
    {
      "parameters": {
        "mode": "insert",
        "pineconeIndex": {
          "__rl": true,
          "value": "muffs",
          "mode": "list",
          "cachedResultName": "muffs"
        },
        "options": {}
      },
      "id": "f8555000-20ac-4dc0-b085-b7429567e4df",
      "name": "Pinecone Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1,
      "position": [
        1152,
        128
      ],
      "credentials": {
        "pineconeApi": {
          "id": "dXlrQiaIHKllMnnh",
          "name": "PineconeApi account"
        }
      }
    },
    {
      "parameters": {
        "resource": "Datasets",
        "datasetId": "={{ $json.defaultDatasetId }}",
        "offset": {},
        "limit": {}
      },
      "type": "@apify/n8n-nodes-apify.apify",
      "typeVersion": 1,
      "position": [
        1072,
        -416
      ],
      "id": "618c1797-88a7-4c76-a46b-bebc40a344f8",
      "name": "Get dataset items",
      "credentials": {
        "apifyApi": {
          "id": "YcBWf1mX5RP5j8UQ",
          "name": "JUNAID SCRAPPER"
        }
      }
    },
    {
      "parameters": {
        "operation": "Get last run",
        "userActorId": {
          "__rl": true,
          "value": "moJRLRc85AitArpNN",
          "mode": "list",
          "cachedResultName": "Web Scraper (apify/web-scraper)",
          "cachedResultUrl": "https://console.apify.com/actors/moJRLRc85AitArpNN/input"
        }
      },
      "type": "@apify/n8n-nodes-apify.apify",
      "typeVersion": 1,
      "position": [
        720,
        -384
      ],
      "id": "dfedde05-37ed-48e7-be4e-5c0305acd79a",
      "name": "Get last run",
      "credentials": {
        "apifyApi": {
          "id": "YcBWf1mX5RP5j8UQ",
          "name": "JUNAID SCRAPPER"
        }
      }
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        0,
        128
      ],
      "id": "a1db7d21-cdfe-4d47-850d-7467de3d0ebb",
      "name": "When clicking ‚ÄòExecute workflow‚Äô"
    },
    {
      "parameters": {
        "jsCode": "// Get input data\nconst items = $input.all();\n\n// Helper function to clean text\nfunction cleanText(text) {\n  if (!text) return '';\n  return text\n    .replace(/\\s+/g, ' ')           // Multiple spaces to single\n    .replace(/\\n+/g, '\\n')          // Multiple newlines to single\n    .replace(/[^\\S\\n]+/g, ' ')      // Normalize whitespace\n    .trim();\n}\n\n// Helper function to check if page is valid\nfunction isValidPage(item) {\n  const data = item.json;\n  \n  // Skip error pages\n  if (data.title?.includes('Application error') || \n      data.rawText?.includes('Digest:') ||\n      data['#error'] === true) {\n    return false;\n  }\n  \n  // Skip pages with minimal content\n  if (!data.rawText || data.rawText.length < 100) {\n    return false;\n  }\n  \n  // Skip duplicate application pages (keep only one)\n  if (data.url?.includes('/apply?c=')) {\n    return false; // We'll keep the main /apply page\n  }\n  \n  return true;\n}\n\n// Helper function to extract main content\nfunction extractMainContent(item) {\n  const data = item.json;\n  \n  // Combine relevant text fields\n  let content = '';\n  \n  // Add title\n  if (data.title) {\n    content += `# ${cleanText(data.title)}\\n\\n`;\n  }\n  \n  // Add meta description\n  if (data.metaDescription) {\n    content += `${cleanText(data.metaDescription)}\\n\\n`;\n  }\n  \n  // Add main headings (H1, H2, H3 only)\n  if (data.headings && data.headings.length > 0) {\n    const mainHeadings = data.headings\n      .filter(h => ['H1', 'H2', 'H3'].includes(h.tag))\n      .map(h => `${'#'.repeat(parseInt(h.tag.slice(1)))} ${cleanText(h.text)}`)\n      .join('\\n');\n    \n    if (mainHeadings) {\n      content += `${mainHeadings}\\n\\n`;\n    }\n  }\n  \n  // Add main content\n  if (data.rawText) {\n    content += cleanText(data.rawText);\n  }\n  \n  // Add course information if available\n  if (data.course?.courseTitle) {\n    content += `\\n\\nCourse: ${data.course.courseTitle}`;\n  }\n  \n  return content;\n}\n\n// Helper function to create metadata\nfunction createMetadata(item) {\n  const data = item.json;\n  \n  return {\n    url: data.url || data.canonical,\n    title: data.title || '',\n    type: data.url?.includes('/courses/') ? 'course' :\n          data.url?.includes('/blog/') ? 'blog' :\n          data.url?.includes('/about') ? 'about' :\n          data.url?.includes('/contact') ? 'contact' : 'page',\n    lastUpdated: new Date().toISOString()\n  };\n}\n\n// Process and deduplicate\nconst processedItems = [];\nconst seenUrls = new Set();\nconst seenContent = new Set();\n\nfor (const item of items) {\n  // Skip invalid pages\n  if (!isValidPage(item)) {\n    continue;\n  }\n  \n  const data = item.json;\n  const canonicalUrl = data.canonical || data.url;\n  \n  // Skip duplicate URLs\n  if (seenUrls.has(canonicalUrl)) {\n    continue;\n  }\n  seenUrls.add(canonicalUrl);\n  \n  // Extract and clean content\n  const content = extractMainContent(item);\n  \n  // Create content hash for duplicate detection\n  const contentHash = content.slice(0, 500); // First 500 chars for comparison\n  \n  // Skip duplicate content\n  if (seenContent.has(contentHash)) {\n    continue;\n  }\n  seenContent.add(contentHash);\n  \n  // Skip if content too short after cleaning\n  if (content.length < 200) {\n    continue;\n  }\n  \n  // Create cleaned item\n  processedItems.push({\n    json: {\n      content: content,\n      metadata: createMetadata(item),\n      wordCount: content.split(/\\s+/).length\n    }\n  });\n}\n\n// Log statistics\nconsole.log(`Original items: ${items.length}`);\nconsole.log(`Cleaned items: ${processedItems.length}`);\nconsole.log(`Removed: ${items.length - processedItems.length}`);\n\nreturn processedItems;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        -304
      ],
      "id": "9595614b-0742-49f5-8db9-54e91514b0d1",
      "name": "Claude1"
    },
    {
      "parameters": {
        "jsCode": "return items\n  .filter(item => item.json.rawText && item.json.rawText.trim() !== \"\") // skip empty pages\n  .map(item => {\n    const { url, title, metaDescription, rawText } = item.json;\n\n    // Clean text: remove extra spaces, line breaks, and non-printable chars\n    const cleanedText = rawText\n      .replace(/\\s+/g, \" \")           // collapse spaces/newlines\n      .replace(/[^\\x20-\\x7E]+/g, \" \") // remove non-ASCII chars\n      .trim();\n\n    // Combine important info for embeddings\n    const content = `${title || \"\"}\\n${metaDescription || \"\"}\\n${cleanedText}`;\n\n    return {\n      json: {\n        id: url,\n        text: content,\n        metadata: {\n          title,\n          url,\n          description: metaDescription\n        }\n      }\n    };\n  });\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        224,
        -304
      ],
      "id": "3d5674c4-6c75-4627-baff-a7cc67dc71c0",
      "name": "chatgpt code"
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import re\nfrom datetime import datetime\nfrom typing import List, Dict, Any\n\n\ndef clean_text(text: str) -> str:\n    \"\"\"Clean text by normalizing whitespace\"\"\"\n    if not text:\n        return ''\n    \n    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces to single\n    text = re.sub(r'\\n+', '\\n', text)  # Multiple newlines to single\n    text = re.sub(r'[^\\S\\n]+', ' ', text)  # Normalize whitespace\n    return text.strip()\n\n\ndef is_valid_page(item: Dict[str, Any]) -> bool:\n    \"\"\"Check if page is valid\"\"\"\n    data = item.get('json', {})\n    \n    # Skip error pages\n    title = data.get('title', '')\n    raw_text = data.get('rawText', '')\n    \n    if 'Application error' in title or 'Digest:' in raw_text or data.get('#error') is True:\n        return False\n    \n    # Skip pages with minimal content\n    if not raw_text or len(raw_text) < 100:\n        return False\n    \n    # Skip duplicate application pages (keep only one)\n    url = data.get('url', '')\n    if '/apply?c=' in url:\n        return False  # We'll keep the main /apply page\n    \n    return True\n\n\ndef extract_main_content(item: Dict[str, Any]) -> str:\n    \"\"\"Extract main content from item\"\"\"\n    data = item.get('json', {})\n    content = ''\n    \n    # Add title\n    if data.get('title'):\n        content += f\"# {clean_text(data['title'])}\\n\\n\"\n    \n    # Add meta description\n    if data.get('metaDescription'):\n        content += f\"{clean_text(data['metaDescription'])}\\n\\n\"\n    \n    # Add main headings (H1, H2, H3 only)\n    headings = data.get('headings', [])\n    if headings:\n        main_headings = []\n        for h in headings:\n            if h.get('tag') in ['H1', 'H2', 'H3']:\n                level = int(h['tag'][1])\n                heading_text = clean_text(h.get('text', ''))\n                main_headings.append(f\"{'#' * level} {heading_text}\")\n        \n        if main_headings:\n            content += '\\n'.join(main_headings) + '\\n\\n'\n    \n    # Add main content\n    if data.get('rawText'):\n        content += clean_text(data['rawText'])\n    \n    # Add course information if available\n    course = data.get('course', {})\n    if course.get('courseTitle'):\n        content += f\"\\n\\nCourse: {course['courseTitle']}\"\n    \n    return content\n\n\ndef create_metadata(item: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Create metadata for item\"\"\"\n    data = item.get('json', {})\n    url = data.get('url') or data.get('canonical', '')\n    \n    # Determine page type\n    if '/courses/' in url:\n        page_type = 'course'\n    elif '/blog/' in url:\n        page_type = 'blog'\n    elif '/about' in url:\n        page_type = 'about'\n    elif '/contact' in url:\n        page_type = 'contact'\n    else:\n        page_type = 'page'\n    \n    return {\n        'url': url,\n        'title': data.get('title', ''),\n        'type': page_type,\n        'lastUpdated': datetime.now().isoformat()\n    }\n\n\ndef process_items(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    \"\"\"Process and deduplicate items\"\"\"\n    processed_items = []\n    seen_urls = set()\n    seen_content = set()\n    \n    for item in items:\n        # Skip invalid pages\n        if not is_valid_page(item):\n            continue\n        \n        data = item.get('json', {})\n        canonical_url = data.get('canonical') or data.get('url', '')\n        \n        # Skip duplicate URLs\n        if canonical_url in seen_urls:\n            continue\n        seen_urls.add(canonical_url)\n        \n        # Extract and clean content\n        content = extract_main_content(item)\n        \n        # Create content hash for duplicate detection\n        content_hash = content[:500]  # First 500 chars for comparison\n        \n        # Skip duplicate content\n        if content_hash in seen_content:\n            continue\n        seen_content.add(content_hash)\n        \n        # Skip if content too short after cleaning\n        if len(content) < 200:\n            continue\n        \n        # Create cleaned item\n        processed_items.append({\n            'json': {\n                'content': content,\n                'metadata': create_metadata(item),\n                'wordCount': len(content.split())\n            }\n        })\n    \n    # Log statistics\n    print(f\"Original items: {len(items)}\")\n    print(f\"Cleaned items: {len(processed_items)}\")\n    print(f\"Removed: {len(items) - len(processed_items)}\")\n    \n    return processed_items\n\n\n# Main execution for n8n\nitems = _input.all()\nprocessed_items = process_items(items)\n\n# Return processed items to n8n\nreturn processed_items"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        0,
        -304
      ],
      "id": "868c73ba-dbd3-4035-80c8-5a2894850b9c",
      "name": "Python"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "1",
        "contextWindowLength": 99
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        576,
        1104
      ],
      "id": "c72c732c-3164-494b-9258-c6805c1b1e0a",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "jsCode": "// n8n Code Node - Data Cleaning for Edify College Website\n// Place this in a Code node after your data input\n\nconst inputData = $input.all();\nconst cleanedData = [];\nconst seenUrls = new Set();\nconst seenContent = new Set();\n\n// Helper function to generate content hash\nfunction generateHash(text) {\n  if (!text) return '';\n  return text.toLowerCase().trim().substring(0, 100);\n}\n\n// Helper function to clean text\nfunction cleanText(text) {\n  if (!text || typeof text !== 'string') return '';\n  return text\n    .replace(/\\s+/g, ' ')\n    .replace(/√¢‚Ç¨‚Ñ¢|√¢‚Ç¨≈ì|√¢‚Ç¨ÔøΩ|√¢‚Ç¨¬¶|√¢‚Ç¨\"/g, match => {\n      const map = {'√¢‚Ç¨‚Ñ¢': \"'\", '√¢‚Ç¨≈ì': '\"', '√¢‚Ç¨ÔøΩ': '\"', '√¢‚Ç¨¬¶': '...', '√¢‚Ç¨\"': '-'};\n      return map[match] || match;\n    })\n    .trim();\n}\n\n// Helper function to check if content is meaningful\nfunction isMeaningfulContent(text) {\n  if (!text) return false;\n  const wordCount = text.split(/\\s+/).length;\n  return wordCount >= 10; // At least 10 words\n}\n\n// Helper function to remove error pages\nfunction isErrorPage(item) {\n  const errorIndicators = [\n    'application error',\n    'server-side exception',\n    'digest:',\n    'error: requesthandler timed out'\n  ];\n  \n  const textToCheck = (item.rawText || '').toLowerCase();\n  return errorIndicators.some(indicator => textToCheck.includes(indicator));\n}\n\n// Process each item\nfor (const item of inputData) {\n  const json = item.json;\n  \n  // Skip if error occurred during scraping\n  if (json['#error'] === true) continue;\n  \n  // Skip error pages\n  if (isErrorPage(json)) continue;\n  \n  // Skip duplicate URLs\n  if (seenUrls.has(json.url)) continue;\n  \n  // Skip if canonical URL is different (it's likely a duplicate)\n  if (json.canonical && json.canonical !== json.url) {\n    if (seenUrls.has(json.canonical)) continue;\n  }\n  \n  // Clean and prepare content\n  const cleanedItem = {\n    url: json.url,\n    canonical: json.canonical || json.url,\n    title: cleanText(json.title),\n    metaDescription: cleanText(json.metaDescription),\n    courseTitle: json.course?.courseTitle ? cleanText(json.course.courseTitle) : null,\n    courseDescription: json.course?.courseDesc ? cleanText(json.course.courseDesc) : null,\n    rawText: cleanText(json.rawText),\n    headings: [],\n    outlineItems: [],\n    internalLinks: json.internalLinks || [],\n    paragraphCount: json.paragraphCount || 0\n  };\n  \n  // Process headings - remove duplicates and empty\n  if (json.headings && Array.isArray(json.headings)) {\n    const seenHeadings = new Set();\n    cleanedItem.headings = json.headings\n      .filter(h => h.text && h.text.trim())\n      .map(h => ({\n        tag: h.tag,\n        text: cleanText(h.text)\n      }))\n      .filter(h => {\n        if (seenHeadings.has(h.text.toLowerCase())) return false;\n        seenHeadings.add(h.text.toLowerCase());\n        return true;\n      });\n  }\n  \n  // Process outline items - remove duplicates\n  if (json.outlineItems && Array.isArray(json.outlineItems)) {\n    const seenOutline = new Set();\n    cleanedItem.outlineItems = json.outlineItems\n      .filter(item => item && item.trim())\n      .map(item => cleanText(item))\n      .filter(item => {\n        const key = item.toLowerCase();\n        if (seenOutline.has(key)) return false;\n        seenOutline.add(key);\n        return isMeaningfulContent(item);\n      });\n  }\n  \n  // Check for duplicate content using hash\n  const contentHash = generateHash(cleanedItem.rawText + cleanedItem.title);\n  if (contentHash && seenContent.has(contentHash)) continue;\n  \n  // Only add if there's meaningful content\n  if (isMeaningfulContent(cleanedItem.rawText) || \n      isMeaningfulContent(cleanedItem.courseDescription) ||\n      cleanedItem.headings.length > 0) {\n    \n    seenUrls.add(json.url);\n    if (contentHash) seenContent.add(contentHash);\n    cleanedData.push(cleanedItem);\n  }\n}\n\n// Return cleaned data\nreturn cleanedData.map(item => ({ json: item }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        128
      ],
      "id": "26fc541b-1108-416f-a0ff-b3682339ae71",
      "name": "latest"
    },
    {
      "parameters": {
        "jsCode": "// n8n Code Node - Chunk Cleaned Data for Pinecone\n// Place this after the cleaning script\n\nconst inputData = $input.all();\nconst chunks = [];\nlet chunkId = 0;\n\n// Configuration\nconst MAX_CHUNK_SIZE = 1000; // characters per chunk\nconst OVERLAP = 100; // overlap between chunks for context\n\n// Helper function to create chunks from text\nfunction createTextChunks(text, maxSize, overlap) {\n  if (!text || text.length <= maxSize) return [text];\n  \n  const result = [];\n  let start = 0;\n  \n  while (start < text.length) {\n    let end = start + maxSize;\n    \n    // Try to break at sentence boundary\n    if (end < text.length) {\n      const sentenceEnd = text.lastIndexOf('. ', end);\n      if (sentenceEnd > start + maxSize / 2) {\n        end = sentenceEnd + 1;\n      }\n    }\n    \n    result.push(text.substring(start, end).trim());\n    start = end - overlap;\n  }\n  \n  return result;\n}\n\n// Process each cleaned item\nfor (const item of inputData) {\n  const data = item.json;\n  \n  // Create main content chunk\n  const mainContent = [\n    data.title,\n    data.metaDescription,\n    data.courseTitle,\n    data.courseDescription\n  ].filter(Boolean).join('\\n\\n');\n  \n  if (mainContent.trim()) {\n    chunks.push({\n      id: `chunk_${chunkId++}`,\n      url: data.url,\n      type: 'header',\n      content: mainContent,\n      metadata: {\n        title: data.title,\n        url: data.url,\n        canonical: data.canonical,\n        courseTitle: data.courseTitle\n      }\n    });\n  }\n  \n  // Chunk the main raw text\n  if (data.rawText && data.rawText.length > 0) {\n    const textChunks = createTextChunks(data.rawText, MAX_CHUNK_SIZE, OVERLAP);\n    \n    textChunks.forEach((chunk, index) => {\n      chunks.push({\n        id: `chunk_${chunkId++}`,\n        url: data.url,\n        type: 'content',\n        content: chunk,\n        chunkIndex: index,\n        totalChunks: textChunks.length,\n        metadata: {\n          title: data.title,\n          url: data.url,\n          canonical: data.canonical,\n          courseTitle: data.courseTitle,\n          chunkPosition: `${index + 1}/${textChunks.length}`\n        }\n      });\n    });\n  }\n  \n  // Create outline chunk if exists\n  if (data.outlineItems && data.outlineItems.length > 0) {\n    const outlineText = data.outlineItems.join('\\n‚Ä¢ ');\n    chunks.push({\n      id: `chunk_${chunkId++}`,\n      url: data.url,\n      type: 'outline',\n      content: `Course Outline:\\n‚Ä¢ ${outlineText}`,\n      metadata: {\n        title: data.title,\n        url: data.url,\n        canonical: data.canonical,\n        courseTitle: data.courseTitle\n      }\n    });\n  }\n  \n  // Create headings structure chunk\n  if (data.headings && data.headings.length > 0) {\n    const headingsText = data.headings\n      .map(h => `${h.tag}: ${h.text}`)\n      .join('\\n');\n    \n    chunks.push({\n      id: `chunk_${chunkId++}`,\n      url: data.url,\n      type: 'structure',\n      content: `Page Structure:\\n${headingsText}`,\n      metadata: {\n        title: data.title,\n        url: data.url,\n        canonical: data.canonical,\n        courseTitle: data.courseTitle\n      }\n    });\n  }\n}\n\n// Return chunks ready for Pinecone\nreturn chunks.map(chunk => ({ json: chunk }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        896,
        128
      ],
      "id": "bc92f91d-45fc-47aa-8e2f-421c0ff69794",
      "name": "chunk splitter"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        448,
        1104
      ],
      "id": "bb78d36b-375d-4b88-8189-77689f02f0ed",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "Btzo19Pm3rnWyDIE",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        688,
        1520
      ],
      "id": "637224c6-8c5c-4e4f-8ba4-f557c4c9efeb",
      "name": "Embeddings OpenAI1",
      "credentials": {
        "openAiApi": {
          "id": "Btzo19Pm3rnWyDIE",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4o-mini",
          "mode": "list",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        896,
        1312
      ],
      "id": "444164f6-d78f-4856-88c6-3f5a7397850e",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "Btzo19Pm3rnWyDIE",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "embed-english-v3.0"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsCohere",
      "typeVersion": 1,
      "position": [
        1120,
        352
      ],
      "id": "e9329844-91a3-43f2-b746-c386138c8518",
      "name": "Embeddings Cohere",
      "credentials": {
        "cohereApi": {
          "id": "qM82BRiYi9xNnlOp",
          "name": "CohereApi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.crawl4ai.com/v1/crawl",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        352,
        128
      ],
      "id": "c8c7f9d2-8fac-4129-8389-dd7741627f05",
      "name": "HTTP Request"
    }
  ],
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "shared": [
    {
      "updatedAt": "2025-11-09T09:52:00.275Z",
      "createdAt": "2025-11-09T09:52:00.275Z",
      "role": "workflow:owner",
      "workflowId": "e93mTToA3deWmhJf",
      "projectId": "POJtR4euQRkudXYs"
    }
  ],
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2025-11-18T20:21:56.000Z",
  "versionId": "07f775f7-c3a1-46dd-882c-93123a8abb22"
}